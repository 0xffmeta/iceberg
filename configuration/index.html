<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://iceberg.apache.org/configuration/">
    <link rel="shortcut icon" href="../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Configuration - Apache Iceberg</title>
    <link href="../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../css/highlight.css">
    <link href="../css/extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../js/jquery-3.2.1.min.js"></script>
    <script src="../js/bootstrap-3.3.7.min.js"></script>
    <script src="../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Configuration", url: "#_top", children: [
              {title: "Table properties", url: "#table-properties" },
              {title: "Catalog properties", url: "#catalog-properties" },
              {title: "Hadoop configuration", url: "#hadoop-configuration" },
          ]},
        ];

    </script>
    <script src="../js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    <!--
 - Licensed to the Apache Software Foundation (ASF) under one or more
 - contributor license agreements.  See the NOTICE file distributed with
 - this work for additional information regarding copyright ownership.
 - The ASF licenses this file to You under the Apache License, Version 2.0
 - (the "License"); you may not use this file except in compliance with
 - the License.  You may obtain a copy of the License at
 -
 -   http://www.apache.org/licenses/LICENSE-2.0
 -
 - Unless required by applicable law or agreed to in writing, software
 - distributed under the License is distributed on an "AS IS" BASIS,
 - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 - See the License for the specific language governing permissions and
 - limitations under the License.
 -->

<h1 id="configuration">Configuration<a class="headerlink" href="#configuration" title="Permanent link">&para;</a></h1>
<h2 id="table-properties">Table properties<a class="headerlink" href="#table-properties" title="Permanent link">&para;</a></h2>
<p>Iceberg tables support table properties to configure table behavior, like the default split size for readers.</p>
<h3 id="read-properties">Read properties<a class="headerlink" href="#read-properties" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>read.split.target-size</td>
<td>134217728 (128 MB)</td>
<td>Target size when combining data input splits</td>
</tr>
<tr>
<td>read.split.metadata-target-size</td>
<td>33554432 (32 MB)</td>
<td>Target size when combining metadata input splits</td>
</tr>
<tr>
<td>read.split.planning-lookback</td>
<td>10</td>
<td>Number of bins to consider when combining input splits</td>
</tr>
<tr>
<td>read.split.open-file-cost</td>
<td>4194304 (4 MB)</td>
<td>The estimated cost to open a file, used as a minimum weight when combining splits.</td>
</tr>
</tbody>
</table>
<h3 id="write-properties">Write properties<a class="headerlink" href="#write-properties" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>write.format.default</td>
<td>parquet</td>
<td>Default file format for the table; parquet, avro, or orc</td>
</tr>
<tr>
<td>write.parquet.row-group-size-bytes</td>
<td>134217728 (128 MB)</td>
<td>Parquet row group size</td>
</tr>
<tr>
<td>write.parquet.page-size-bytes</td>
<td>1048576 (1 MB)</td>
<td>Parquet page size</td>
</tr>
<tr>
<td>write.parquet.dict-size-bytes</td>
<td>2097152 (2 MB)</td>
<td>Parquet dictionary page size</td>
</tr>
<tr>
<td>write.parquet.compression-codec</td>
<td>gzip</td>
<td>Parquet compression codec</td>
</tr>
<tr>
<td>write.parquet.compression-level</td>
<td>null</td>
<td>Parquet compression level</td>
</tr>
<tr>
<td>write.avro.compression-codec</td>
<td>gzip</td>
<td>Avro compression codec</td>
</tr>
<tr>
<td>write.location-provider.impl</td>
<td>null</td>
<td>Optional custom implemention for LocationProvider</td>
</tr>
<tr>
<td>write.metadata.compression-codec</td>
<td>none</td>
<td>Metadata compression codec; none or gzip</td>
</tr>
<tr>
<td>write.metadata.metrics.default</td>
<td>truncate(16)</td>
<td>Default metrics mode for all columns in the table; none, counts, truncate(length), or full</td>
</tr>
<tr>
<td>write.metadata.metrics.column.col1</td>
<td>(not set)</td>
<td>Metrics mode for column &lsquo;col1&rsquo; to allow per-column tuning; none, counts, truncate(length), or full</td>
</tr>
<tr>
<td>write.target-file-size-bytes</td>
<td>536870912 (512 MB)</td>
<td>Controls the size of files generated to target about this many bytes</td>
</tr>
<tr>
<td>write.distribution-mode</td>
<td>none</td>
<td>Defines distribution of write data: <strong>none</strong>: don&rsquo;t shuffle rows; <strong>hash</strong>: hash distribute by partition key ; <strong>range</strong>: range distribute by partition key or sort key if table has an SortOrder</td>
</tr>
<tr>
<td>write.wap.enabled</td>
<td>false</td>
<td>Enables write-audit-publish writes</td>
</tr>
<tr>
<td>write.summary.partition-limit</td>
<td>0</td>
<td>Includes partition-level summary stats in snapshot summaries if the changed partition count is less than this limit</td>
</tr>
<tr>
<td>write.metadata.delete-after-commit.enabled</td>
<td>false</td>
<td>Controls whether to delete the oldest version metadata files after commit</td>
</tr>
<tr>
<td>write.metadata.previous-versions-max</td>
<td>100</td>
<td>The max number of previous version metadata files to keep before deleting after commit</td>
</tr>
<tr>
<td>write.spark.fanout.enabled</td>
<td>false</td>
<td>Enables Partitioned-Fanout-Writer writes in Spark</td>
</tr>
</tbody>
</table>
<h3 id="table-behavior-properties">Table behavior properties<a class="headerlink" href="#table-behavior-properties" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>commit.retry.num-retries</td>
<td>4</td>
<td>Number of times to retry a commit before failing</td>
</tr>
<tr>
<td>commit.retry.min-wait-ms</td>
<td>100</td>
<td>Minimum time in milliseconds to wait before retrying a commit</td>
</tr>
<tr>
<td>commit.retry.max-wait-ms</td>
<td>60000 (1 min)</td>
<td>Maximum time in milliseconds to wait before retrying a commit</td>
</tr>
<tr>
<td>commit.retry.total-timeout-ms</td>
<td>1800000 (30 min)</td>
<td>Maximum time in milliseconds to wait before retrying a commit</td>
</tr>
<tr>
<td>commit.status-check.num-retries</td>
<td>3</td>
<td>Number of times to check whether a commit succeeded after a connection is lost before failing due to an unknown commit state</td>
</tr>
<tr>
<td>commit.status-check.min-wait-ms</td>
<td>1000 (1s)</td>
<td>Minimum time in milliseconds to wait before retrying a status-check</td>
</tr>
<tr>
<td>commit.status-check.max-wait-ms</td>
<td>60000 (1 min)</td>
<td>Maximum time in milliseconds to wait before retrying a status-check</td>
</tr>
<tr>
<td>commit.status-check.total-timeout-ms</td>
<td>1800000 (30 min)</td>
<td>Maximum time in milliseconds to wait before retrying a status-check</td>
</tr>
<tr>
<td>commit.manifest.target-size-bytes</td>
<td>8388608 (8 MB)</td>
<td>Target size when merging manifest files</td>
</tr>
<tr>
<td>commit.manifest.min-count-to-merge</td>
<td>100</td>
<td>Minimum number of manifests to accumulate before merging</td>
</tr>
<tr>
<td>commit.manifest-merge.enabled</td>
<td>true</td>
<td>Controls whether to automatically merge manifests on writes</td>
</tr>
<tr>
<td>history.expire.max-snapshot-age-ms</td>
<td>432000000 (5 days)</td>
<td>Default max age of snapshots to keep while expiring snapshots</td>
</tr>
<tr>
<td>history.expire.min-snapshots-to-keep</td>
<td>1</td>
<td>Default min number of snapshots to keep while expiring snapshots</td>
</tr>
</tbody>
</table>
<h3 id="compatibility-flags">Compatibility flags<a class="headerlink" href="#compatibility-flags" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>compatibility.snapshot-id-inheritance.enabled</td>
<td>false</td>
<td>Enables committing snapshots without explicit snapshot IDs</td>
</tr>
</tbody>
</table>
<h2 id="catalog-properties">Catalog properties<a class="headerlink" href="#catalog-properties" title="Permanent link">&para;</a></h2>
<p>Iceberg catalogs support using catalog properties to configure catalog behaviors. Here is a list of commonly used catalog properties:</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>catalog-impl</td>
<td>null</td>
<td>a custom <code>Catalog</code> implementation to use by an engine</td>
</tr>
<tr>
<td>io-impl</td>
<td>null</td>
<td>a custom <code>FileIO</code> implementation to use in a catalog</td>
</tr>
<tr>
<td>warehouse</td>
<td>null</td>
<td>the root path of the data warehouse</td>
</tr>
<tr>
<td>uri</td>
<td>null</td>
<td>a URI string, such as Hive metastore URI</td>
</tr>
<tr>
<td>clients</td>
<td>2</td>
<td>client pool size</td>
</tr>
</tbody>
</table>
<p><code>HadoopCatalog</code> and <code>HiveCatalog</code> can access the properties in their constructors.
Any other custom catalog can access the properties by implementing <code>Catalog.initialize(catalogName, catalogProperties)</code>.
The properties can be manually constructed or passed in from a compute engine like Spark or Flink.
Spark uses its session properties as catalog properties, see more details in the <a href="../spark-configuration/#catalog-configuration">Spark configuration</a> section.
Flink passes in catalog properties through <code>CREATE CATALOG</code> statement, see more details in the <a href="../flink/#creating-catalogs-and-using-catalogs">Flink</a> section.</p>
<h3 id="lock-catalog-properties">Lock catalog properties<a class="headerlink" href="#lock-catalog-properties" title="Permanent link">&para;</a></h3>
<p>Here are the catalog properties related to locking. They are used by some catalog implementations to control the locking behavior during commits.</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>lock-impl</td>
<td>null</td>
<td>a custom implementation of the lock manager, the actual interface depends on the catalog used</td>
</tr>
<tr>
<td>lock.table</td>
<td>null</td>
<td>an auxiliary table for locking, such as in <a href="../aws/#dynamodb-for-commit-locking">AWS DynamoDB lock manager</a></td>
</tr>
<tr>
<td>lock.acquire-interval-ms</td>
<td>5 seconds</td>
<td>the interval to wait between each attempt to acquire a lock</td>
</tr>
<tr>
<td>lock.acquire-timeout-ms</td>
<td>3 minutes</td>
<td>the maximum time to try acquiring a lock</td>
</tr>
<tr>
<td>lock.heartbeat-interval-ms</td>
<td>3 seconds</td>
<td>the interval to wait between each heartbeat after acquiring a lock</td>
</tr>
<tr>
<td>lock.heartbeat-timeout-ms</td>
<td>15 seconds</td>
<td>the maximum time without a heartbeat to consider a lock expired</td>
</tr>
</tbody>
</table>
<h2 id="hadoop-configuration">Hadoop configuration<a class="headerlink" href="#hadoop-configuration" title="Permanent link">&para;</a></h2>
<p>The following properties from the Hadoop configuration are used by the Hive Metastore connector.</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>iceberg.hive.client-pool-size</td>
<td>5</td>
<td>The size of the Hive client pool when tracking tables in HMS</td>
</tr>
<tr>
<td>iceberg.hive.lock-timeout-ms</td>
<td>180000 (3 min)</td>
<td>Maximum time in milliseconds to acquire a lock</td>
</tr>
<tr>
<td>iceberg.hive.lock-check-min-wait-ms</td>
<td>50</td>
<td>Minimum time in milliseconds to check back on the status of lock acquisition</td>
</tr>
<tr>
<td>iceberg.hive.lock-check-max-wait-ms</td>
<td>5000</td>
<td>Maximum time in milliseconds to check back on the status of lock acquisition</td>
</tr>
</tbody>
</table>
<p>Note: <code>iceberg.hive.lock-check-max-wait-ms</code> should be less than the <a href="https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.txn.timeout">transaction timeout</a> 
of the Hive Metastore (<code>hive.txn.timeout</code> or <code>metastore.txn.timeout</code> in the newer versions). Otherwise, the heartbeats on the lock (which happens during the lock checks) would end up expiring in the 
Hive Metastore before the lock is retried from Iceberg.</p>

  <br>
</div>

<footer class="container-fluid wm-page-content"><p>Copyright 2018-2021 <a href='https://www.apache.org/'>The Apache Software Foundation</a><br />Apache Iceberg, Iceberg, Apache, the Apache feather logo, and the Apache Iceberg project logo are either registered<br />trademarks or trademarks of The Apache Software Foundation in the United States and other countries.</p>
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>