<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://iceberg.apache.org/getting-started/">
    <link rel="shortcut icon" href="../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Getting Started - Apache Iceberg</title>
    <link href="../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../css/highlight.css">
    <link href="../css/extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../js/jquery-3.2.1.min.js"></script>
    <script src="../js/bootstrap-3.3.7.min.js"></script>
    <script src="../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Getting Started", url: "#_top", children: [
              {title: "Using Iceberg in Spark 3", url: "#using-iceberg-in-spark-3" },
          ]},
        ];

    </script>
    <script src="../js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    <!--
 - Licensed to the Apache Software Foundation (ASF) under one or more
 - contributor license agreements.  See the NOTICE file distributed with
 - this work for additional information regarding copyright ownership.
 - The ASF licenses this file to You under the Apache License, Version 2.0
 - (the "License"); you may not use this file except in compliance with
 - the License.  You may obtain a copy of the License at
 -
 -   http://www.apache.org/licenses/LICENSE-2.0
 -
 - Unless required by applicable law or agreed to in writing, software
 - distributed under the License is distributed on an "AS IS" BASIS,
 - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 - See the License for the specific language governing permissions and
 - limitations under the License.
 -->

<h1 id="getting-started">Getting Started<a class="headerlink" href="#getting-started" title="Permanent link">&para;</a></h1>
<p>The latest version of Iceberg is <a href="../releases/">0.12.0</a>.</p>
<p>Spark is currently the most feature-rich compute engine for Iceberg operations. 
We recommend you to get started with Spark to understand Iceberg concepts and features with examples.
You can also view documentations of using Iceberg with other compute engine under the <strong>Engines</strong> tab.</p>
<h2 id="using-iceberg-in-spark-3">Using Iceberg in Spark 3<a class="headerlink" href="#using-iceberg-in-spark-3" title="Permanent link">&para;</a></h2>
<p>To use Iceberg in a Spark shell, use the <code>--packages</code> option:</p>
<pre><code class="language-sh">spark-shell --packages org.apache.iceberg:iceberg-spark3-runtime:0.12.0
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you want to include Iceberg in your Spark installation, add the <a href="https://search.maven.org/remotecontent?filepath=org/apache/iceberg/iceberg-spark3-runtime/0.12.0/iceberg-spark3-runtime-0.12.0.jar"><code>iceberg-spark3-runtime</code> Jar</a> to Spark&rsquo;s <code>jars</code> folder.</p>
</div>
<h3 id="adding-catalogs">Adding catalogs<a class="headerlink" href="#adding-catalogs" title="Permanent link">&para;</a></h3>
<p>Iceberg comes with <a href="../spark-configuration/#catalogs">catalogs</a> that enable SQL commands to manage tables and load them by name. Catalogs are configured using properties under <code>spark.sql.catalog.(catalog_name)</code>.</p>
<p>This command creates a path-based catalog named <code>local</code> for tables under <code>$PWD/warehouse</code> and adds support for Iceberg tables to Spark&rsquo;s built-in catalog:</p>
<pre><code class="language-sh">spark-sql --packages org.apache.iceberg:iceberg-spark3-runtime:0.12.0\
    --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
    --conf spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog \
    --conf spark.sql.catalog.spark_catalog.type=hive \
    --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
    --conf spark.sql.catalog.local.type=hadoop \
    --conf spark.sql.catalog.local.warehouse=$PWD/warehouse
</code></pre>
<h3 id="creating-a-table">Creating a table<a class="headerlink" href="#creating-a-table" title="Permanent link">&para;</a></h3>
<p>To create your first Iceberg table in Spark, use the <code>spark-sql</code> shell or <code>spark.sql(...)</code> to run a <a href="../spark-ddl/#create-table"><code>CREATE TABLE</code></a> command:</p>
<pre><code class="language-sql">-- local is the path-based catalog defined above
CREATE TABLE local.db.table (id bigint, data string) USING iceberg
</code></pre>
<p>Iceberg catalogs support the full range of SQL DDL commands, including:</p>
<ul>
<li><a href="../spark-ddl/#create-table"><code>CREATE TABLE ... PARTITIONED BY</code></a></li>
<li><a href="../spark-ddl/#create-table-as-select"><code>CREATE TABLE ... AS SELECT</code></a></li>
<li><a href="../spark-ddl/#alter-table"><code>ALTER TABLE</code></a></li>
<li><a href="../spark-ddl/#drop-table"><code>DROP TABLE</code></a></li>
</ul>
<h3 id="writing">Writing<a class="headerlink" href="#writing" title="Permanent link">&para;</a></h3>
<p>Once your table is created, insert data using <a href="../spark-writes/#insert-into"><code>INSERT INTO</code></a>:</p>
<pre><code class="language-sql">INSERT INTO local.db.table VALUES (1, 'a'), (2, 'b'), (3, 'c');
INSERT INTO local.db.table SELECT id, data FROM source WHERE length(data) = 1;
</code></pre>
<p>Iceberg also adds row-level SQL updates to Spark, <a href="../spark-writes/#merge-into"><code>MERGE INTO</code></a> and <a href="../spark-writes/#delete-from"><code>DELETE FROM</code></a>:</p>
<pre><code class="language-sql">MERGE INTO local.db.target t USING (SELECT * FROM updates) u ON t.id = u.id
WHEN MATCHED THEN UPDATE SET t.count = t.count + u.count
WHEN NOT MATCHED THEN INSERT *
</code></pre>
<p>Iceberg supports writing DataFrames using the new <a href="../spark-writes/#writing-with-dataframes">v2 DataFrame write API</a>:</p>
<pre><code class="language-scala">spark.table(&quot;source&quot;).select(&quot;id&quot;, &quot;data&quot;)
     .writeTo(&quot;local.db.table&quot;).append()
</code></pre>
<p>The old <code>write</code> API is supported, but <em>not</em> recommended.</p>
<h3 id="reading">Reading<a class="headerlink" href="#reading" title="Permanent link">&para;</a></h3>
<p>To read with SQL, use the an Iceberg table name in a <code>SELECT</code> query:</p>
<pre><code class="language-sql">SELECT count(1) as count, data
FROM local.db.table
GROUP BY data
</code></pre>
<p>SQL is also the recommended way to <a href="../spark-queries/#inspecting-tables">inspect tables</a>. To view all of the snapshots in a table, use the <code>snapshots</code> metadata table:</p>
<pre><code class="language-sql">SELECT * FROM local.db.table.snapshots
</code></pre>
<pre><code>+-------------------------+----------------+-----------+-----------+----------------------------------------------------+-----+
| committed_at            | snapshot_id    | parent_id | operation | manifest_list                                      | ... |
+-------------------------+----------------+-----------+-----------+----------------------------------------------------+-----+
| 2019-02-08 03:29:51.215 | 57897183625154 | null      | append    | s3://.../table/metadata/snap-57897183625154-1.avro | ... |
|                         |                |           |           |                                                    | ... |
|                         |                |           |           |                                                    | ... |
| ...                     | ...            | ...       | ...       | ...                                                | ... |
+-------------------------+----------------+-----------+-----------+----------------------------------------------------+-----+
</code></pre>
<p><a href="../spark-queries/#querying-with-dataframes">DataFrame reads</a> are supported and can now reference tables by name using <code>spark.table</code>:</p>
<pre><code class="language-scala">val df = spark.table(&quot;local.db.table&quot;)
df.count()
</code></pre>
<h3 id="next-steps">Next steps<a class="headerlink" href="#next-steps" title="Permanent link">&para;</a></h3>
<p>Next, you can learn more about Iceberg tables in Spark:</p>
<ul>
<li><a href="../spark-ddl/">DDL commands</a>: <code>CREATE</code>, <code>ALTER</code>, and <code>DROP</code></li>
<li><a href="../spark-queries/">Querying data</a>: <code>SELECT</code> queries and metadata tables</li>
<li><a href="../spark-writes/">Writing data</a>: <code>INSERT INTO</code> and <code>MERGE INTO</code></li>
<li><a href="../spark-procedures/">Maintaining tables</a> with stored procedures</li>
</ul>

  <br>
</div>

<footer class="container-fluid wm-page-content"><p>Copyright 2018-2021 <a href='https://www.apache.org/'>The Apache Software Foundation</a><br />Apache Iceberg, Iceberg, Apache, the Apache feather logo, and the Apache Iceberg project logo are either registered<br />trademarks or trademarks of The Apache Software Foundation in the United States and other countries.</p>
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>